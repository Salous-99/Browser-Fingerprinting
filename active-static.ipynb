{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from ua_parser import user_agent_parser\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from statistics import mean \n",
    "from fuzzywuzzy import fuzz\n",
    "import math \n",
    "import operator\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from IPython import display\n",
    "from base64 import b64decode\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import base64\n",
    "import random\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from difflib import SequenceMatcher\n",
    "import time\n",
    "import datetime\n",
    "import uuid \n",
    "from pyjarowinkler import distance\n",
    "%matplotlib inline\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f6cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# saved locally, no connection over network \n",
    "conn = sqlite3.connect('../../bfp-pets-2020.sqlite')\n",
    "cursor = conn.cursor()\n",
    "print(\"Opened database successfully\")\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following function will receive a dataframe and an list of the needed attributes\n",
    "# the function will then append the \"id_measurement\" and \"measurement_datetime\" (which are\n",
    "# not entropy values for attributes so they will never appear naturally and must be manually\n",
    "# appened so that they can be included in the dataset)\n",
    "\n",
    "# After appending the values needed, the return value is the same dataframe without all the\n",
    "# attributes not included in columns, also sorted in ascending order by the measurement_datetime\n",
    "def createDataSet(measurements, columns = []):\n",
    "    columns.append(\"id_measurement\")\n",
    "    columns.append(\"measurement_datetime\")\n",
    "    return measurements[columns].sort_values(by = 'measurement_datetime')\n",
    "\n",
    "\n",
    "# Entropy values are imported from the csv file (entropy calculation done separetly in another notebook)\n",
    "header_list = [\"field\", \"entropy\",\"normalizedEntropy\"]\n",
    "entropies = pd.read_csv('../allEntropiesNew.csv', names=header_list)\n",
    "\n",
    "# Entropy values must not contain a field that is id_measurement, measurement_datetime, or id_user as those\n",
    "# values for field give no information about the browsing environment with respect to its fingerprint\n",
    "# furthermore, the stemmed values are also excluded\n",
    "entropies = entropies[(entropies[\"field\"] != \"id_measurement\") & (entropies[\"field\"] != \"measurement_datetime\") & (entropies[\"field\"] != \"id_user\") & (~entropies.field.str.contains(\"stemmed\"))]\n",
    "\n",
    "# entropy values are sorted in descending order by theit normalized entropy values\n",
    "entropies = entropies.sort_values(by='normalizedEntropy', ascending=False)\n",
    "\n",
    "# this function returns a list of N attributes with the highest entropy values\n",
    "def getNBestAttributes(N):\n",
    "    return entropies['field'].tolist()[:N]\n",
    "\n",
    "# this function splits the dataframe contained in data into two chunks:\n",
    "# 0 to numOrFloat, or if numOrFloat is a precentage from 0.0 to 1.0 then\n",
    "# from 0 to size(dataset) * numOrFloat, and the other chunk being the rest\n",
    "# of the data\n",
    "def chronologicalSplit(numOrFloat, data):\n",
    "    \n",
    "    num = 37762\n",
    "    \n",
    "    if isinstance(numOrFloat, int):\n",
    "        if numOrFloat < 0:\n",
    "            num = 37762 - numOrFloat\n",
    "        elif numOrFloat > 0:\n",
    "            num = numOrFloat\n",
    "    elif isinstance(numOrFloat, float):\n",
    "        num = int(numOrFloat * num)\n",
    "    \n",
    "    return data.iloc[:num, :], data.iloc[num:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd83143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# service function that returns the user_id from the fingerprint\n",
    "def getUserIDFromRecordID(fp):\n",
    "    return fp[\"id_user\"].values[0]\n",
    "\n",
    "# service function that gets a time in second and returns time in format\n",
    "def human_time(secs):\n",
    "    units = [(\"day\", 86400), (\"hour\", 3600), (\"minute\", 60), (\"second\", 1)]\n",
    "    parts = []\n",
    "    for unit, mul in units:\n",
    "        if secs / mul >= 1 or mul == 1:\n",
    "            if mul > 1:\n",
    "                n = int(math.floor(secs / mul))\n",
    "                secs -= n * mul\n",
    "            else:\n",
    "                n = secs if secs != int(secs) else int(secs)\n",
    "            parts.append(\"%s %s%s\" % (n, unit, \"\" if n == 1 else \"s\"))\n",
    "    return \", \".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following block contains the code needed for the nodes of the linked list\n",
    "# each node contains a fingerprint ID, a precentage match to the previous fingerprint\n",
    "# a pointer/reference to the next fingerprint node.\n",
    "class FpNode:\n",
    "    def __init__(self, fp, percentageMatchToPreviousFp = None):\n",
    "        self.fp = fp\n",
    "        self.fpID = fp[\"id_measurement\"].values[0];\n",
    "        self.next = None\n",
    "        self.percentageMatchToPreviousFp = percentageMatchToPreviousFp\n",
    "        \n",
    "    def insertAfter(self, newFpNode):\n",
    "        # if inserting at the end, overwrite the none with the reference to the new node\n",
    "        if self.next == None:\n",
    "            self.next = newFpNode\n",
    "        \n",
    "        # otherwise, store the pre-existing next in a temorary varaible, insert the new node\n",
    "        # and restore the old next\n",
    "        else:\n",
    "            nextNode = self.next\n",
    "            self.next = newFpNode\n",
    "            newFpNode.next = nextNode\n",
    "            \n",
    "# the following code block contains the code for the linked list. Each linked list\n",
    "# is associated with a browser environments and contains all the associated nodes\n",
    "# a linked list has an associated ID (randomly generated), and a reference to the\n",
    "# first and last fingerprint node in the list\n",
    "class FpLinkedList:\n",
    "    def __init__(self, generatedUserID,firstFp, latestFp):\n",
    "        self.firstFp = firstFp\n",
    "        self.generatedUserID = generatedUserID;\n",
    "        self.latestFp = latestFp\n",
    "    \n",
    "    # getter\n",
    "    def getUserID(self):\n",
    "        return self.generatedUserID;\n",
    "    \n",
    "    # getter\n",
    "    def getLatestFp(self):\n",
    "        return self.latestFp\n",
    "    \n",
    "    # service function to print all the node IDs in the list\n",
    "    def traverse_list(self):\n",
    "        if self.firstFp is None:\n",
    "            print(\"List has no element\")\n",
    "            return\n",
    "        else:\n",
    "            n = self.firstFp\n",
    "            while n is not None:\n",
    "                if n.next is not None:\n",
    "                    print(n.fpID , \"--> \", end = \"\")\n",
    "                else:\n",
    "                    print(n.fpID)\n",
    "                n = n.next\n",
    "    \n",
    "    # Inserting node at end\n",
    "    def insertAtEnd(self, newFpNode):\n",
    "        if self.firstFp is None:\n",
    "            self.firstFp = newFpNode\n",
    "            self.lastFp = newFpNode\n",
    "            return\n",
    "        else:\n",
    "            self.latestFp.next = newFpNode\n",
    "            self.latestFp = newFpNode\n",
    "            \n",
    "    def getClosestFp(self, new_fp):\n",
    "        timestamp = new_fp['measurement_datetime']        \n",
    "        n = self.firstFp\n",
    "        \n",
    "        timeDifference = abs(n.fp['measurement_datetime'] - timestamp)\n",
    "        nearestFpNode = n\n",
    "        \n",
    "        while n is not None:\n",
    "            if(abs(n.fp['measurement_datetime'] - timestamp) < timeDifference):\n",
    "                timeDifference = abs(n.fp['measurement_datetime'] - timestamp)\n",
    "                nearestFpNode = n\n",
    "                n = n.next\n",
    "                \n",
    "        return nearestFp.fp\n",
    "    \n",
    "    def printAccuracy(self,fp):\n",
    "        if self.firstFp is None:\n",
    "            return\n",
    "        else:\n",
    "            correctCounter = 0\n",
    "            counter = 0\n",
    "            n = self.firstFp.next\n",
    "            prev = self.firstFp\n",
    "            while n is not None:\n",
    "                groundTruthN = getUserIDFromRecordID(n.fp);\n",
    "                groundTruthPrev = getUserIDFromRecordID(prev.fp);\n",
    "                if(groundTruthN == groundTruthPrev):\n",
    "                    correctCounter += 1\n",
    "                        \n",
    "                counter += 1\n",
    "                prev = n\n",
    "                n = n.next\n",
    "                \n",
    "            if(counter > 1):    \n",
    "                print((float(correctCounter/counter) * 100.0), \"% accuracy\")\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c6624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns true of the jaro_distance is above the threshold, false otherwise\n",
    "# recieves as its arguments, two strings that hold the value of attributes\n",
    "# in two fingerprints\n",
    "def JaroWinklerSimilarity(val1,val2, threshold = 0.8, useExactValueForJaccardIndex = False):\n",
    "    ratio = distance.get_jaro_distance(val1, val2, winkler=False, scaling=0.1)\n",
    "    if(useExactValueForJaccardIndex):\n",
    "        return ratio\n",
    "    if(ratio > threshold):\n",
    "        return True;\n",
    "    else:\n",
    "        return False;\n",
    "\n",
    "# this function takes in an attribute name and two values for that attribute\n",
    "# in two different fingerprints, and it returns true or false or the exact\n",
    "# value for the JaroWinkler similarity score (depedning on the flag \"useExactValueForJaccardIndex\")\n",
    "def matchAttributes(attributeName, value1, value2, useExactValueForJaccardIndex = False):\n",
    "    # If the value being compared is one of the following: js_useragent,\n",
    "    # http_useragent, or js_screen_resolution_avail_whcp, a specific \n",
    "    # comparison threshold is used (or in the case of the last one, an exact match)\n",
    "    # if any other attribute is used, a default of exact match is used.\n",
    "    attributeToAlgorithmMap = {\n",
    "        \"js_useragent\" : { \n",
    "            \"matchType\" : \"similarity\",\n",
    "            \"threshold\" : 0.8\n",
    "        },\n",
    "        \"http_useragent\": { \n",
    "            \"matchType\" : \"similarity\",\n",
    "            \"threshold\" : 0.8\n",
    "        },\n",
    "        \"js_screen_resolution_avail_whcp\" :{ \n",
    "            \"matchType\" : \"exactEqual\",\n",
    "        },\n",
    "        \"default\" : { # shouldn't this be similairty baed with threshold of 0.9?\n",
    "            \"matchType\" : \"exactEqual\"\n",
    "            # \"threshold\" : 0.9\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # uses the map to load into data\n",
    "    data = attributeToAlgorithmMap[\"default\"]\n",
    "    if attributeName in attributeToAlgorithmMap:\n",
    "        data = attributeToAlgorithmMap[attributeName]\n",
    "    \n",
    "    # depending on the value of data, either a specific match, or JaroWinkler similarity\n",
    "    # algorithm is used\n",
    "    if (data[\"matchType\"] == \"similarity\"):\n",
    "        return JaroWinklerSimilarity(value1, value2, data[\"threshold\"], useExactValueForJaccardIndex)\n",
    "    elif(data[\"matchType\"] == \"exactEqual\"):\n",
    "        return value1 == value2;\n",
    "\n",
    "# wrapper function that handles the jaccard similarity index for all attributes in two\n",
    "# fingerprints and returns a value between 0 and 1.0 that is the jaccard similarity index\n",
    "def JaccardIndex(new_fp, latest_fp, D, useExactValueForJaccardIndex = False):\n",
    "    # remove unnecssary columns\n",
    "    s1 = new_fp.drop(columns=['id_measurement', 'measurement_datetime'])\n",
    "    s2 = latest_fp.drop(columns=['id_measurement', 'measurement_datetime'])\n",
    "    \n",
    "    # create a list of all attributes (should be 25)\n",
    "    s1Columns = list(s1.columns) \n",
    "    similaritySum = 0;\n",
    "\n",
    "    for s1Col in s1Columns:\n",
    "        # get the values in the two fingerprints\n",
    "        s1ColValue = str(s1[s1Col].values[0])\n",
    "        s2ColValue = str(s2[s1Col].values[0])\n",
    "        \n",
    "        # skip if either value is null\n",
    "        if(s1ColValue == \"\" or s2ColValue == \"\"):\n",
    "            continue;\n",
    "\n",
    "        # run the matching algorithm for the two values\n",
    "        runMatch = matchAttributes(s1Col, s1ColValue, s2ColValue, useExactValueForJaccardIndex);\n",
    "        \n",
    "        # if useExactValueForJaccardIndex is False then runMatch will just be a true or false value\n",
    "        # as sich we just increment the similaritySum when True\n",
    "        if(runMatch == True):\n",
    "            similaritySum += 1\n",
    "            \n",
    "        # if useExactValueForJaccardIndex is True then we will get a float from matchAttributes that\n",
    "        # we just add to the smiilary sum\n",
    "        elif (type(runMatch) == float):\n",
    "            similaritySum += runMatch\n",
    "        \n",
    "    totalNumAttributes = len(s1Columns)\n",
    "    \n",
    "    return (similaritySum / ((totalNumAttributes*2) - similaritySum))\n",
    "\n",
    "# Iterates over the jaccard similarity scores for all possible fingerprints\n",
    "# and returns the ID of the fingerprint with the highest Jaccard similarity index\n",
    "# iff that similarity index is larger than the threshold, if not, None is returned\n",
    "def JaccardMatchCriteria(scores, threshold = 0.8):\n",
    "    currentMaxScore = 0\n",
    "    currentMaxID = 0\n",
    "    for fakeUserID in scores:\n",
    "        if scores[fakeUserID] > currentMaxScore:\n",
    "            currentMaxScore = scores[fakeUserID]\n",
    "            currentMaxID = fakeUserID\n",
    "    \n",
    "    print(\"\\t highest score found: \", currentMaxScore)\n",
    "    if totalMatchesDone > 0:\n",
    "        print(\"\\t current acc = (\", totalCorrectMatches, \"/\", totalMatchesDone, \")*100 = \", (totalCorrectMatches/totalMatchesDone)*100, \"%\")\n",
    "    if(currentMaxScore > threshold):        \n",
    "        return {\n",
    "            \"topMatchUserID\" : currentMaxID\n",
    "        };\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# recieves two fingerprints and returns True if the two browser fingerprints came from\n",
    "# the same OS (or if either fingerprints does not have http_useragent)\n",
    "def isFromSameOperatingSystem(temp_fp, latest_fp):\n",
    "    s1 = temp_fp\n",
    "    s2 = latest_fp\n",
    "\n",
    "    if(('http_useragent' not in s1) or ('http_useragent' not in s2)):\n",
    "        return True\n",
    "    else:\n",
    "        osFamS1 = user_agent_parser.ParseOS(s1['http_useragent'].values[0])['family']\n",
    "        osFamS2 = user_agent_parser.ParseOS(s2['http_useragent'].values[0])['family']\n",
    "        \n",
    "        if(osFamS1 == osFamS2):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae501cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack function, this is a dynamic attack since the fingerprints are given chronologically\n",
    "# from oldest to newest\n",
    "def attack(X, X_arr, new_fp, scoringFunction, matchCriteria, useExactValueForJaccardIndex = False, getMatchMetaData = False, threshold = 0.8, filePath = \"test.txt\" , startTime = time.time()):\n",
    "    global totalMatchesDone \n",
    "    global totalCorrectMatches\n",
    "\n",
    "    # this is the code that runs when a new browsing environment is found (which is guarnteed\n",
    "    # to happen first time)\n",
    "    \n",
    "    if (len(X) == 0):\n",
    "        newUserID = uuid.uuid1()  # random unique ID is generated\n",
    "        fpNode = FpNode(new_fp)       # first node is created and passed to the node constructor\n",
    "        newFpLinkedList = FpLinkedList(newUserID, fpNode, fpNode) # new linked list is created and the userID as well as the\n",
    "                                                                  # node are passed note that the first and last Fp are both \n",
    "                                                                  # fpNode as this is a new list with only one node\n",
    "                \n",
    "        X[newUserID] = newFpLinkedList # new browsing environment is added to the dictionary\n",
    "        X_arr.append(newUserID)        # new user ID is added to the array\n",
    "        \n",
    "    globalTemp = {} # unsure of what this does\n",
    "    matchMetaData = [] # only needed if getMatchMetaData is True but keep it\n",
    "    \n",
    "    # keep iterating while you still have data in the dataset\n",
    "    tempScores = {} # tempScores is the dictionary that holds as its key, the browsing environments ID / user IDs\n",
    "                    # and as its value, the similarity score between the current fingerprint and the latest fp\n",
    "                    # of each browsing environment or linked list\n",
    "\n",
    "\n",
    "    # iterate over all user IDs that are known\n",
    "    for fakeUserID in reversed(X_arr):\n",
    "        # if the two fingerprints are not from the same OS they are definitely not from the same browser\n",
    "        # set score to zero and continue\n",
    "        if not isFromSameOperatingSystem(new_fp, X[fakeUserID].getLatestFp().fp):\n",
    "            tempScores[fakeUserID] = 0;\n",
    "            continue;\n",
    "\n",
    "        # add the score of each browsing environment\n",
    "        tempScores[fakeUserID] = scoringFunction(new_fp, X[fakeUserID].getClosestFp(), useExactValueForJaccardIndex) # returns score for specific fake userID\n",
    "\n",
    "        # if metaData is required, add it\n",
    "        if getMatchMetaData:\n",
    "            b = X[fakeUserID].getLatestFp().fp\n",
    "            trueMatch = getUserIDFromRecordID(new_fp) == getUserIDFromRecordID(bID)\n",
    "            matchMetaData.append({\n",
    "               \"fpA_id\" :  temp_id,\n",
    "                \"fpB_id\" : bID,\n",
    "                \"score\" : tempScores[fakeUserID],\n",
    "                \"groundTruthMatch\" : trueMatch,\n",
    "                \"fpA_device\" : mobileOrDesktop(temp_id),\n",
    "                \"fpB_device\" : mobileOrDesktop(bID),\n",
    "            });\n",
    "\n",
    "        # if we get a perfect match of 1, we break early and skip all subsequent fingerprints\n",
    "        if tempScores[fakeUserID] == 1:\n",
    "            break;\n",
    "\n",
    "    # we iterate over all scores and return the ID of the highest matching browsing environment\n",
    "    runMatchCriteria = matchCriteria(tempScores, threshold) #returns keys topMatchUserID\n",
    "\n",
    "\n",
    "    # printing progress status\n",
    "    if(index % 100) == 0:\n",
    "        appendString = \"\\nIteration: \" + str(index);\n",
    "        if totalMatchesDone > 0:\n",
    "            perc = (totalCorrectMatches/totalMatchesDone)*100;\n",
    "            appendString += \"\\n\\t acc = (\" + str(totalCorrectMatches) + \"/\" + str(totalMatchesDone) + \") * 100 = \" + str(perc) + \"%\";\n",
    "        appendString += \"\\n\\t no. of browsing env = \" + str(len(X_arr))\n",
    "        #appendString += \"\\n\\t total matches computed: \" + str(len(matchMetaData))\n",
    "        curTime = time.time()\n",
    "        appendString += \"\\n\\t time taken so far: \"+ human_time(curTime - startTime)\n",
    "        appendString += \"\\n\\t (\" + str(index) + \"/\" + str(len(D)) + \") * 100 = \" + str((index / len(D))* 100) + \" % complete\"\n",
    "        appendString += \"\\n--------------------------------------------\"\n",
    "\n",
    "        with open(filePath, 'a+') as file:\n",
    "            file.seek(0)\n",
    "            content = file.read()\n",
    "            if appendString not in content:\n",
    "                file.write(appendString)\n",
    "\n",
    "    # if runMatchCriteria is not None, meaning the matchCriteria function returned an ID\n",
    "    # we instantiate a new node, and append this new node to the corresponding linked list\n",
    "    if(runMatchCriteria != None):\n",
    "        totalMatchesDone += 1\n",
    "        newFpNode = FpNode(temp_id, tempScores[fakeUserID])\n",
    "\n",
    "        # we first fetch the old fingerprint ID\n",
    "        oldFpID = X[runMatchCriteria['topMatchUserID']].getLatestFp().fpID\n",
    "        #append the new one\n",
    "        X[runMatchCriteria['topMatchUserID']].insertAtEnd(newFpNode)\n",
    "\n",
    "        # compare the user ID of both to see if the match is correct\n",
    "        groundTruthS1 = getUserIDFromRecordID(temp_id, dataset)\n",
    "        groundTruthS2 = getUserIDFromRecordID(oldFpID, dataset)\n",
    "        print(\"\\t\\ttemp_id\",temp_id,\"oldFpID\",oldFpID)\n",
    "        print(\"\\t\\tgroundTruthS1\",groundTruthS1,\"groundTruthS2\",groundTruthS2)\n",
    "\n",
    "        # if match is correct, increment the correct matches counter\n",
    "        if groundTruthS1 == groundTruthS2:\n",
    "            totalCorrectMatches += 1\n",
    "\n",
    "    # if matchCriteria did return None, then this a is a new browsing environment so the\n",
    "    # program does what it did initially, which is make a new instance of a browser fingerprint\n",
    "    else:\n",
    "        newFakeUserID = uuid.uuid1()\n",
    "        fpNode = FpNode(temp_id)  \n",
    "        newFpLinkedList = FpLinkedList(newFakeUserID, fpNode, fpNode)\n",
    "        X[newFakeUserID] = newFpLinkedList\n",
    "        X_arr.append(newFakeUserID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c913e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a wrapper function used to run the attack.\n",
    "def testAttack(size, attr_num = 25, threshold = 0.6):\n",
    "    \n",
    "    # load all measurements in dataframe (2D datastructure given by pandas library)\n",
    "    measurements =  pd.read_sql_query(\"SELECT * FROM measurements\", conn)\n",
    "\n",
    "    startTime = time.time()\n",
    "    \n",
    "    global totalMatchesDone = 0 \n",
    "    global totalCorrectMatches = 0\n",
    "    \n",
    "    dataset, d2 = chronologicalSplit(0.8, createDataSet(measurements, getNBestAttributes(attr_num)))\n",
    "    datasetGroundTruthed , d3 = chronologicalSplit(size, createDataSet(measurements, ['id_user']))\n",
    "    \n",
    "    groundTruth_number_of_users = datasetGroundTruthed['id_user'].nunique()\n",
    "    \n",
    "    path = \"attack7_results/results_\"+ str(attr_num) + \"attrs_\" + str(threshold) +\"threshold_\" + str(size) +\"size.txt\"\n",
    "    \n",
    "    global structuredDataSet = {}\n",
    "    global BrowsingEnvironmentIDs = []\n",
    "    global matchMetaData\n",
    "    \n",
    "    index = 0;\n",
    "    while(index != len(dataset)){\n",
    "        new_fp = dataset.iloc[[index]]\n",
    "        attack(structuredDataSet, BrowsingEnvironmentIDs, new_fp, JaccardIndex, JaccardMatchCriteria, False, False, threshold, path, startTime)\n",
    "        index += 1\n",
    "    }\n",
    "    \n",
    "    endTime = time.time()\n",
    "    percentageAcc = (totalCorrectMatches/totalMatchesDone)*100;\n",
    "    appendString = \"\\nThreshold: \" + str(threshold) + \" | Records: \" + str(size) + \" | Top \" + str(attr_num) + \" Attributes\";\n",
    "    appendString += \"\\n\\t acc = (\" + str(totalCorrectMatches) + \"/\" + str(totalMatchesDone) + \") * 100 = \" + str(percentageAcc) + \"%\";\n",
    "    appendString += \"\\n\\t total matches computed: \" + str(len(metaData))\n",
    "    appendString += \"\\n\\t number of users in ground truth: \" + str(groundTruth_number_of_users)\n",
    "    appendString += \"\\n\\t number of browsing environments found: \" + str(len(attackResults))\n",
    "    appendString +=  \"\\n\\tTotal time taken: \" + human_time(endTime - startTime)\n",
    "    \n",
    "    path = \"attack7_results/finalResults_\"+ str(attr_num) + \"attrs_\" + str(threshold) +\"threshold_\" + str(size) +\"size.txt\"\n",
    "    \n",
    "    with open(path, 'a+') as file:\n",
    "        file.seek(0)\n",
    "        content = file.read()\n",
    "        if appendString not in content:\n",
    "            file.write(appendString)\n",
    "    print(appendString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testAttack(37762, 25, 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
